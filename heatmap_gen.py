# -*- coding: utf-8 -*-
"""FML_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zMH5UzWgWQqebOHgfQeD5f_i2Fle0cog
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import os
import tensorflow as tf
import cv2
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import Input
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import InputLayer, Flatten, Dense, Dropout, LeakyReLU
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D
#from tensorflow.keras.layers.advanced_activations import LeakyReLU
from tensorflow.keras.layers import BatchNormalization
from  matplotlib import pyplot as plt
import matplotlib.image as mpimg
from tensorflow.keras.models import load_model
# %matplotlib inline
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib as mpl
#from google.colab import drive
#drive.mount('/content/gdrive')



IMG_WIDTH = 200
IMG_HEIGHT = 200
train_file = r'tt_data\train'
test_file = r'tt_data\test'
print('start')
def create_test_dataset(img_folder):
   
    img_data_array=[]
    class_name=[]
   
    for file in os.listdir(img_folder):
        image_path= os.path.join(img_folder, file)
        for img in os.listdir(image_path):
            image_path_= os.path.join(image_path, img)
            image= cv2.imread( image_path_, cv2.COLOR_BGR2RGB)
            #image= cv2.imread( image_path, 0)
            #cv2.imshow('image',image)
            #print(image_path_)
            #print(type(image))
            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)
        #image = image.reshape(IMG_HEIGHT, IMG_WIDTH, 1)
        #print(image.shape)
            image=np.array(image)
            image = image.astype('float32')
            image /= 255 
            img_data_array.append(image)
            class_name.append(file.split('_')[0])
            #print(file.split('_')[0])
    print("\n")
    return np.array(img_data_array), np.array(class_name)


test_data, test_class_name = create_test_dataset(test_file)
print('Testing data shape : ', test_data.shape, test_class_name.shape)
print(test_class_name.shape)


print(test_class_name)
print(type(test_class_name))
classes = np.unique(test_class_name)
nClasses = len(classes)
print('Total number of outputs : ', nClasses)
print('Output classes : ', classes)

print(test_class_name)
target_dict = {
    'nothing': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10,
    'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21,
    'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26, 'del': 27, 'space': 28 
}

list_Y = []
for i in test_class_name:
  list_Y.append(target_dict[i])
test_Y = np.array(list_Y)
del list_Y[:]
print('$$$$$$$$$')
print(test_Y)


model_ = load_model('model_s1_2.h5')

y_pred = np.argmax(model_.predict(test_data), axis=-1)
print(y_pred)


cm = confusion_matrix(test_Y, y_pred)
print(cm)
'''
def matrix_heatmap(data):
	axis = sns.heatmap(data, linewidth=0.5)
	plt.show()
	
	
#data = np.random.rand(10, 12)
matrix_heatmap(cm)
'''

def matrix_heatmap(data):
	axis = sns.heatmap(data, linewidth=0.5)
	l1=['Nothing']
	for i in range(26):
		l1.append(chr(97 + i))
	l1.append('del')
	l1.append('space')
	plt.xticks(range(29),l1)
	plt.yticks(range(29),l1)
	axis.tick_params(axis='x', pad=15)
	axis.tick_params(axis='y', pad=15)
	mpl.rcParams['xtick.major.pad'] = 12
	mpl.rcParams['ytick.major.pad'] = 12
	plt.setp(axis.get_yticklabels(), rotation=30, horizontalalignment='right')

	plt.show()
	plt.save('heatmap.png')
#data = np.random.rand(29,29)
matrix_heatmap(cm)
