# -*- coding: utf-8 -*-
"""FML_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zMH5UzWgWQqebOHgfQeD5f_i2Fle0cog
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import os
import tensorflow as tf
import cv2
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import Input
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import InputLayer, Flatten, Dense, Dropout, LeakyReLU
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D
#from tensorflow.keras.layers.advanced_activations import LeakyReLU
from tensorflow.keras.layers import BatchNormalization
from  matplotlib import pyplot as plt
import matplotlib.image as mpimg
from tensorflow.keras.models import load_model
# %matplotlib inline

#from google.colab import drive
#drive.mount('/content/gdrive')



IMG_WIDTH = 200
IMG_HEIGHT = 200
train_file = r'tt_data\train'
test_file = r'tt_data\test'
print('tomar')
'''
def create_train_dataset(img_folder):
   
    img_data_array=[]
    class_name=[]
    i=0
    for dir1 in os.listdir(img_folder):
        #print(dir1)
        #ctr = 1
        image_path= os.path.join(img_folder, dir1)
        for file in os.listdir(image_path):
            #if ctr > 500:
            #    break
            #else:
            #ctr=ctr+1
            image_path= os.path.join(image_path,file)
            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)
                #image= cv2.imread( image_path, 0)
                #cv2.imshow('image',image)
            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)
                #image = image.reshape(IMG_HEIGHT, IMG_WIDTH, 1)
                #print(image.shape)
            image=np.array(image)
            image = image.astype('float32')
            image /= 255 
            img_data_array.append(image)
            class_name.append(file.split('_')[0])
                #i=i+1
                #print(i, end=" ")
        print("\n")
    print('train_data done')
    return np.array(img_data_array), np.array(class_name)
    '''
def create_train_dataset(img_folder):
   
    img_data_array=[]
    class_name=[]
   
    for file in os.listdir(img_folder):
        #print(dir1)
        image_path= os.path.join(img_folder, file)
        for img in os.listdir(image_path):
            image_path_= os.path.join(image_path, img)
            image= cv2.imread( image_path_, cv2.COLOR_BGR2RGB)
            #image= cv2.imread( image_path, 0)
            #cv2.imshow('image',image)
            #print(image_path_)
            #print(type(image))
            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)
        #image = image.reshape(IMG_HEIGHT, IMG_WIDTH, 1)
        #print(image.shape)
            image=np.array(image)
            image = image.astype('float32')
            image /= 255 
            img_data_array.append(image)
            class_name.append(file.split('_')[0])
            #print(file.split('_')[0])
    print('train_data done')
    return np.array(img_data_array), np.array(class_name)
def create_test_dataset(img_folder):
   
    img_data_array=[]
    class_name=[]
   
    for file in os.listdir(img_folder):
        #print(dir1)
        image_path= os.path.join(img_folder, file)
        for img in os.listdir(image_path):
            image_path_= os.path.join(image_path, img)
            image= cv2.imread( image_path_, cv2.COLOR_BGR2RGB)
            #image= cv2.imread( image_path, 0)
            #cv2.imshow('image',image)
            #print(image_path_)
            #print(type(image))
            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)
        #image = image.reshape(IMG_HEIGHT, IMG_WIDTH, 1)
        #print(image.shape)
            image=np.array(image)
            image = image.astype('float32')
            image /= 255 
            img_data_array.append(image)
            class_name.append(file.split('_')[0])
            #print(file.split('_')[0])
    print('test_data done')
    return np.array(img_data_array), np.array(class_name)

# extract the image array and class name

print('training data...')
train_data, train_class_name = create_train_dataset(train_file)
print('Training data shape : ', train_data.shape, train_class_name.shape)

test_data, test_class_name = create_test_dataset(test_file)
print('Testing data shape : ', test_data.shape, test_class_name.shape)

print(train_class_name)
classes = np.unique(train_class_name)
nClasses = len(classes)
print('Total number of outputs : ', nClasses)
print('Output classes : ', classes)

print(train_class_name)
target_dict = {
    'nothing': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10,
    'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21,
    'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26, 'del': 27, 'space': 28 
}

list_Y = []
for i in train_class_name:
  list_Y.append(target_dict[i])
train_Y = np.array(list_Y)
del list_Y[:]

for i in test_class_name:
  list_Y.append(target_dict[i])
test_Y = np.array(list_Y)
del list_Y[:]

#print(train_Y)
print(test_Y)

# Change the labels from categorical to one-hot encoding
train_Y_one_hot = to_categorical(train_Y)
test_Y_one_hot = to_categorical(test_Y)

# Display the change for category label using one-hot encoding
print('Original label:', train_Y[0])
print('After conversion to one-hot:', train_Y_one_hot[0])

from sklearn.model_selection import train_test_split
train_X,valid_X,train_label,valid_label = train_test_split(train_data, train_Y_one_hot, test_size=0.2, random_state=13)

batch_size = 32
epochs = 10
num_classes = 29
print('model generation....')
fashion_model = Sequential()
fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(200,200,3),padding='same'))
fashion_model.add(LeakyReLU(alpha=0.1))
fashion_model.add(MaxPooling2D((2, 2),padding='same'))
fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))
fashion_model.add(LeakyReLU(alpha=0.1))
fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))
fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))
fashion_model.add(LeakyReLU(alpha=0.1))                  
fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))
fashion_model.add(Flatten())
fashion_model.add(Dense(128, activation='linear'))
fashion_model.add(LeakyReLU(alpha=0.1))                  
fashion_model.add(Dense(num_classes, activation='softmax'))
print('model compilation....')
fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])
print('model summary..')
fashion_model.summary()
print('training start...')
callbacks = ModelCheckpoint(save_best_only=True, monitor='val_loss')
history = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,callbacks=[callbacks],verbose=2,validation_data=(valid_X, valid_label))

#import pickle

#with open("models_.pickle", "wb") as f:
#    pickle.dump(fashion_model, f)

#pickle_in = open("models_.pickle", "rb")
#model_ = pickle.load(pickle_in)

fashion_model.save("model_s1_2.h5")
print('load model....')
model_ = load_model('model_s1_2.h5')
#y_pred = model1.predict(x_test)
print('evaluate...')
test_eval = model_.evaluate(test_data, test_Y_one_hot, verbose=2)
print('Test loss:', test_eval[0])
print('Test accuracy:', test_eval[1])


print('gerate fig...')
plt.figure(0)
plt.plot(history.history['accuracy'],label='training accuracy')
plt.plot(history.history['val_accuracy'],label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.savefig('Accuracy1.png')
plt.figure(1)
plt.plot(history.history['loss'],label='training loss')
plt.plot(history.history['val_loss'],label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()
plt.savefig('loss1.png')
print('done')

'''
print('graph generate...')
accuracy = fashion_train.history['accuracy']
val_accuracy = fashion_train.history['val_accuracy']
loss = fashion_train.history['loss']
val_loss = fashion_train.history['val_loss']
epochs = range(len(accuracy))
plt.figure(0)
plt.plot(epochs, accuracy, 'bo', label='Training accuracy')
plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.savefig('Accuracy.png')
plt.figure(1)
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.savefig('loss.png')
#plt.show()
'''
